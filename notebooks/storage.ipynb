{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mjboothaus/personal-tan-lea-kuan/blob/main/notebooks/storage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxLxoGGRto8v"
      },
      "source": [
        "## S3 Object Storage (on Scaleway.com)\n",
        "\n",
        "75GB of free object storage (S3) storage is available on Scaleway.\n",
        "\n",
        "https://www.simplecto.com/using-django-and-boto3-with-scaleway-object-storage/\n",
        "\n",
        "* `ACCESS_KEY_ID` and `SECRET_ACCESS_KEY` can be obtained from the [credentials control panel](https://console.scaleway.com/project/credentials) under API Keys.\n",
        "* `STORAGE_BUCKET_NAME` is the name of the bucket you create on [objects administration page](https://console.scaleway.com/object-storage/buckets)\n",
        "* `DEFAULT_ACL` is set to public-read so that the objects can be pulled from a URL without any access keys or time-limited signatures.\n",
        "* `S3_REGION_NAME` and `S3_ENDPOINT_URL` should be configured so that `boto3` knows to point to the Scaleway resources.\n",
        "\n",
        "All of these are references in the Scaleway's docs on Object Storage.\n",
        "\n",
        "### Resources:\n",
        "* https://www.scaleway.com/en/docs/object-storage-feature/\n",
        "* https://www.scaleway.com/en/docs/how-to-migrate-object-storage-buckets-with-rclone/\n",
        "* https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bd55yV-Fezo4"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.9.7 64-bit ('base': conda)' requires ipykernel package.\n",
            "Run the following command to install 'ipykernel' into the Python environment. \n",
            "Command: 'conda install -n base ipykernel --update-deps --force-reinstall'"
          ]
        }
      ],
      "source": [
        "from dynaconf import settings\n",
        "from pathlib import Path\n",
        "import boto3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hhKBLtKGtkKo",
        "outputId": "d737cc08-d5fe-4b07-889f-096db453cf88"
      },
      "outputs": [],
      "source": [
        "ACCESS_KEY_ID = settings.S3.ACCESS_KEY_ID\n",
        "SECRET_ACCESS_KEY = settings.S3.SECRET_ACCESS_KEY\n",
        "BUCKET_NAME = settings.S3.BUCKET_NAME\n",
        "DEFAULT_ACL = settings.S3.DEFAULT_ACL\n",
        "REGION_NAME = settings.S3.REGION_NAME\n",
        "ENDPOINT_URL =  settings.S3.ENDPOINT_URL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aR7TbuyV8bkr"
      },
      "outputs": [],
      "source": [
        "#from os import path, makedirs\n",
        "from botocore.exceptions import ClientError\n",
        "#from boto3.exceptions import S3TransferFailedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "musDwftk2NUx",
        "outputId": "1ad4bbaa-3c46-4375-ee00-808f5e60b8b7"
      },
      "outputs": [],
      "source": [
        "s3 = boto3.client('s3', \n",
        "        region_name=REGION_NAME, \n",
        "        endpoint_url=ENDPOINT_URL, \n",
        "        aws_access_key_id=ACCESS_KEY_ID,\n",
        "        aws_secret_access_key=SECRET_ACCESS_KEY)\n",
        "\n",
        "\n",
        "#s3_session = boto3.Session(region_name=REGION_NAME)\n",
        "\n",
        "#resource = s3_session.resource(\"s3\",\n",
        "#    endpoint_url=S3_URL,\n",
        "#    aws_access_key_id=SCW_ACCESS_KEY_S3,\n",
        "#    aws_secret_access_key=SCW_SECRET_KEY_S3\n",
        "#)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import s3fs\n",
        "\n",
        "s3 = s3fs.S3FileSystem(\n",
        "   key=ACCESS_KEY_ID,\n",
        "   secret=SECRET_ACCESS_KEY,\n",
        "   client_kwargs={\n",
        "      'endpoint_url': ENDPOINT_URL,\n",
        "      'region_name': REGION_NAME\n",
        "   }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "def upload_file_to_S3(bucket, file_path, s3_bucket_filename, s3client):\n",
        "    #client = resource.meta.client\n",
        "    obj_list = s3client.list_objects(Bucket=bucket.name)\n",
        "    \n",
        "    if \"Contents\" not in obj_list.keys():\n",
        "        print(f'uploading file: {s3_bucket_filename}')\n",
        "        with open(file_path, \"rb\") as f:\n",
        "            bucket.upload_fileobj(f, s3_bucket_filename, ExtraArgs={'ACL':'public-read'})\n",
        "    else:\n",
        "        obj_key = [ key[\"Key\"] for key in client.list_objects(Bucket=bucket.name)[\"Contents\"] ]\n",
        "        if s3_bucket_filename not in obj_key:\n",
        "            print(f'uploading file: {s3_bucket_filename}')\n",
        "            with open(file_path, \"rb\") as f:\n",
        "                bucket.upload_fileobj(f, s3_bucket_filename, ExtraArgs={'ACL':'public-read'})\n",
        "        else:\n",
        "            print(f'file already exists: {s3_bucket_filename}')\n",
        "    \n",
        "    return f\"{bucket.name}/{s3_bucket_filename}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'name'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_4507/3452686701.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mupload_file_to_S3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBUCKET_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gitpod.env\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gitpod.env.txt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipykernel_4507/3906907311.py\u001b[0m in \u001b[0;36mupload_file_to_S3\u001b[0;34m(bucket, file_path, s3_bucket_filename, s3client)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mupload_file_to_S3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms3_bucket_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms3client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#client = resource.meta.client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mobj_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms3client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBucket\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbucket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"Contents\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'name'"
          ]
        }
      ],
      "source": [
        "upload_file_to_S3(BUCKET_NAME, \"gitpod.env\", \"gitpod.env.txt\", s3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "T5qqtl989rnL"
      },
      "outputs": [],
      "source": [
        "def download_s3_folder(s3, bucket_name, s3_folder, local_dir=None):\n",
        "    filecount = 0\n",
        "    files = []\n",
        "    if not local_dir.exists():\n",
        "        Path.makedirs(local_dir)\n",
        "    bucket_list=s3.list_objects(Bucket=bucket_name)['Contents']\n",
        "    for s3_key in bucket_list:\n",
        "        s3_object = s3_key['Key']\n",
        "        if not s3_object.endswith(\"/\"):\n",
        "            filepath = Path(local_dir)/s3_object\n",
        "            s3.download_file(bucket_name, s3_object, filepath.as_posix())\n",
        "            filecount+=1\n",
        "            files.append(s3_object)\n",
        "        else:\n",
        "            if not (Path(local_dir)/s3_object).exists():\n",
        "                Path.makedirs(Path(local_dir)/s3_object)\n",
        "    return filecount, files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "UFftUjTu8GLz"
      },
      "outputs": [],
      "source": [
        "# filecount, files = download_s3_folder(s3, BUCKET_NAME, REPO_NAME, Path.home()/'tmp')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94bId9E5ezpE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "storage.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "5a932f0131bd3b37022744170b7486e17b0c51aecfe809390bb226b827fce3db"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit ('dbooth': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
